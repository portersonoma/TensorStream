{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e26b46a-7847-4bef-8e61-265b2d9e1c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üåç Chipping tiles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1911/1911 [03:17<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1911 tiles processed from Wildcat_Creek.\n",
      "üßπ 1252 black/void tiles skipped (not saved, but tracked for stitching).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# üß© Step 1: Chip TIFFs and Rasterize Masks\n",
    "#\n",
    "# This step creates 1600x1600 image/mask tiles from each map set\n",
    "# - Uses 10% overlap (stride = 1440)\n",
    "# - Includes background-only tiles\n",
    "# - Rasterizes shapefile features to create mask chips\n",
    "# - Outputs tile metadata for later preview and reconstruction\n",
    "#\n",
    "# Outputs:\n",
    "# - /[Map Folder]/tiled/images/\n",
    "# - /[Map Folder]/tiled/masks/\n",
    "# - /[Map Folder]/tiled/tile_metadata.csv\n",
    "# - /[Map Folder]/tiled/raster_shape.txt\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# --- List of all map sets (Updated) ---\n",
    "\"\"\"\n",
    "all_maps = [\n",
    "    \"Bear_Creek_20250112\",\n",
    "    \"Bear_Lane\",\n",
    "    \"Flight_2\",\n",
    "    \"Flight_2_25pct\",\n",
    "    \"Project_2024_09_20\",\n",
    "    \"SFLBC\",\n",
    "    \"Sugar_Refugia_20241112\",\n",
    "    \"Wildcat_Creek\"\n",
    "]\n",
    "\"\"\"\n",
    "# --- Configuration ---\n",
    "map_folder = \"Wildcat_Creek\"\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/\"\n",
    "chip_size = 1600\n",
    "stride = 1280\n",
    "\n",
    "# Original ‚Üí YOLO class IDs\n",
    "class_remap = {\n",
    "    1: 0,  # Road\n",
    "    2: 1,  # PVeg\n",
    "    3: 2   # Water\n",
    "}\n",
    "\n",
    "map_base = os.path.join(base_dir, map_folder)\n",
    "tif_path = os.path.join(map_base, f\"{map_folder}.tiff\")\n",
    "shp_path = os.path.join(map_base, f\"{map_folder}.shp\")\n",
    "\n",
    "out_img_dir = os.path.join(map_base, \"tiled\", \"images\")\n",
    "out_mask_dir = os.path.join(map_base, \"tiled\", \"masks\")\n",
    "meta_csv = os.path.join(map_base, \"tiled\", \"tile_metadata.csv\")\n",
    "shape_txt = os.path.join(map_base, \"tiled\", \"raster_shape.txt\")\n",
    "\n",
    "# --- Clean old data ---\n",
    "for path in [out_img_dir, out_mask_dir]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "os.makedirs(out_img_dir, exist_ok=True)\n",
    "os.makedirs(out_mask_dir, exist_ok=True)\n",
    "\n",
    "if os.path.exists(meta_csv):\n",
    "    os.remove(meta_csv)\n",
    "if os.path.exists(shape_txt):\n",
    "    os.remove(shape_txt)\n",
    "\n",
    "# --- Open raster and store shape ---\n",
    "with rasterio.open(tif_path) as raster:\n",
    "    raster_height, raster_width = raster.height, raster.width\n",
    "    raster_crs = raster.crs\n",
    "    with open(shape_txt, \"w\") as f:\n",
    "        f.write(f\"{raster_height},{raster_width}\")\n",
    "\n",
    "# --- Load and reproject shapefile ---\n",
    "labels = gpd.read_file(shp_path).to_crs(raster_crs)\n",
    "sindex = labels.sindex\n",
    "\n",
    "# --- Begin processing ---\n",
    "results = []\n",
    "skipped = 0\n",
    "\n",
    "with rasterio.open(tif_path) as raster:\n",
    "    for idx, (y, x) in enumerate(tqdm(\n",
    "        [(y, x) for y in range(0, raster_height - chip_size + 1, stride)\n",
    "                 for x in range(0, raster_width - chip_size + 1, stride)],\n",
    "        desc=\"üåç Chipping tiles\"\n",
    "    )):\n",
    "        window = Window(x, y, chip_size, chip_size)\n",
    "        transform = raster.window_transform(window)\n",
    "        bounds = box(*rasterio.windows.bounds(window, raster.transform))\n",
    "\n",
    "        # Read image chip\n",
    "        img = raster.read([1, 2, 3], window=window)\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img_name = f\"chip_{idx}.png\"\n",
    "\n",
    "        # --- Skip writing black tiles, but keep metadata ---\n",
    "        if np.mean(img) < 5 and np.std(img) < 2:\n",
    "            skipped += 1\n",
    "            results.append((img_name, x, y))\n",
    "            continue\n",
    "\n",
    "        # Save image\n",
    "        cv2.imwrite(os.path.join(out_img_dir, img_name), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Rasterize mask\n",
    "        possible_matches = labels.iloc[list(sindex.intersection(bounds.bounds))]\n",
    "        intersecting = possible_matches[possible_matches.intersects(bounds)]\n",
    "        if not intersecting.empty:\n",
    "            shapes = [\n",
    "                (geom, class_remap.get(cid, 255))\n",
    "                for geom, cid in zip(intersecting.geometry, intersecting[\"class_id\"])\n",
    "            ]\n",
    "            mask = rasterize(\n",
    "                shapes,\n",
    "                out_shape=(chip_size, chip_size),\n",
    "                transform=transform,\n",
    "                fill=255,\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "        else:\n",
    "            mask = np.full((chip_size, chip_size), 255, dtype=np.uint8)\n",
    "\n",
    "        cv2.imwrite(os.path.join(out_mask_dir, img_name), mask)\n",
    "        results.append((img_name, x, y))\n",
    "\n",
    "# --- Save metadata ---\n",
    "with open(meta_csv, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"x\", \"y\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"‚úÖ {len(results)} tiles processed from {map_folder}.\")\n",
    "print(f\"üßπ {skipped} black/void tiles skipped (not saved, but tracked for stitching).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123181b0-3436-432b-b206-e601b00a9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Converting: Bear_Creek_20250112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bear_Creek_20250112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1533/1533 [02:11<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bear_Creek_20250112 summary:\n",
      "   - 1433 labeled tiles\n",
      "   - 100 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Bear_Lane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bear_Lane: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [00:54<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bear_Lane summary:\n",
      "   - 530 labeled tiles\n",
      "   - 18 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Flight_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flight_2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1710/1710 [02:22<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flight_2 summary:\n",
      "   - 1188 labeled tiles\n",
      "   - 522 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Flight_2_25pct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flight_2_25pct: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [00:15<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flight_2_25pct summary:\n",
      "   - 133 labeled tiles\n",
      "   - 4 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Project_2024_09_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Project_2024_09_20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1101/1101 [01:33<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project_2024_09_20 summary:\n",
      "   - 966 labeled tiles\n",
      "   - 135 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: SFLBC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SFLBC: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1620/1620 [02:17<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SFLBC summary:\n",
      "   - 1321 labeled tiles\n",
      "   - 299 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Sugar_Refugia_20241112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sugar_Refugia_20241112: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 610/610 [00:59<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sugar_Refugia_20241112 summary:\n",
      "   - 558 labeled tiles\n",
      "   - 52 background-only tiles\n",
      "   - 0 errors\n",
      "\n",
      "üß© Converting: Wildcat_Creek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wildcat_Creek: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 659/659 [00:50<00:00, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wildcat_Creek summary:\n",
      "   - 481 labeled tiles\n",
      "   - 178 background-only tiles\n",
      "   - 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# ‚ö° Step 2: Convert Mask Tiles to YOLOv8 Polygon Labels\n",
    "#\n",
    "# This step converts rasterized mask tiles into YOLOv8-style\n",
    "# polygon .txt labels, enabling training with segmentation models.\n",
    "#\n",
    "# For each map folder:\n",
    "# - Loads corresponding image and mask tiles\n",
    "# - Resizes both to 640√ó640 (matching YOLOv8 input size)\n",
    "# - Extracts external contours for each class in the mask\n",
    "# - Writes polygons in YOLO format:\n",
    "#     ‚Ä¢ class_id x1 y1 x2 y2 ... xn yn (normalized coordinates)\n",
    "#\n",
    "# Enhancements:\n",
    "# - Runs in parallel using multithreading for speed\n",
    "# - Background-only tiles are preserved with empty label files\n",
    "# - Automatically splits 70/30 into train and val subsets\n",
    "#\n",
    "# Input:\n",
    "# - /[map]/tiled/images/      ‚Üê RGB tiles\n",
    "# - /[map]/tiled/masks/       ‚Üê Grayscale masks (class IDs)\n",
    "#\n",
    "# Output:\n",
    "# - /[map]/yolo_dataset_640/images/train/val/\n",
    "# - /[map]/yolo_dataset_640/labels/train/val/\n",
    "#\n",
    "# Notes:\n",
    "# - Supports 3-class masks: 0 = Water, 1 = Road, 2 = PVeg\n",
    "# - No remapping is needed if classes are already 0-based\n",
    "# - This format is compatible with YOLOv8-seg training\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- Updated list of map sets ---\n",
    "all_maps = [\n",
    "    \"Bear_Creek_20250112\",\n",
    "    \"Bear_Lane\",\n",
    "    \"Flight_2\",\n",
    "    \"Flight_2_25pct\",\n",
    "    \"Project_2024_09_20\",\n",
    "    \"SFLBC\",\n",
    "    \"Sugar_Refugia_20241112\",\n",
    "    \"Wildcat_Creek\"\n",
    "]\n",
    "\n",
    "validation_set = \"Flight_2\"\n",
    "\n",
    "# --- Configuration ---\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/\"\n",
    "target_size = 1024\n",
    "num_threads = 8\n",
    "\n",
    "\n",
    "def mask_to_polygons(mask):\n",
    "    contours = {}\n",
    "    for cls_id in np.unique(mask):\n",
    "        if cls_id == 255:\n",
    "            continue\n",
    "        binary = (mask == cls_id).astype(np.uint8)\n",
    "        cnts, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if cnts:\n",
    "            contours[cls_id] = cnts\n",
    "    return contours\n",
    "\n",
    "def process_file(fname, img_input_dir, mask_input_dir, img_out, lbl_out):\n",
    "    img_path = os.path.join(img_input_dir, fname)\n",
    "    mask_path = os.path.join(mask_input_dir, fname)\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None or mask is None:\n",
    "            return \"error\"\n",
    "\n",
    "        img_resized = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "        mask_resized = cv2.resize(mask, (target_size, target_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        label_path = os.path.join(lbl_out, fname.replace(\".png\", \".txt\"))\n",
    "        contours = mask_to_polygons(mask_resized)\n",
    "\n",
    "        # Save image\n",
    "        cv2.imwrite(os.path.join(img_out, fname), img_resized)\n",
    "\n",
    "        # Write label file\n",
    "        with open(label_path, \"w\") as f:\n",
    "            if not contours:\n",
    "                return \"background\"\n",
    "            for cls_id, cnts in contours.items():\n",
    "                for cnt in cnts:\n",
    "                    if len(cnt) < 3:\n",
    "                        continue\n",
    "                    pts = cnt.reshape(-1, 2).astype(np.float32) / target_size\n",
    "                    coords = \" \".join(f\"{x:.6f} {y:.6f}\" for x, y in pts)\n",
    "                    f.write(f\"{cls_id} {coords}\\n\")\n",
    "\n",
    "        return \"labeled\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {fname}: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "# --- Process each map ---\n",
    "for map_folder in all_maps:\n",
    "    print(f\"\\nüß© Converting: {map_folder}\")\n",
    "\n",
    "    base_map_dir = os.path.join(base_dir, map_folder)\n",
    "    img_input_dir = os.path.join(base_map_dir, \"tiled\", \"images\")\n",
    "    mask_input_dir = os.path.join(base_map_dir, \"tiled\", \"masks\")\n",
    "    out_base = os.path.join(base_map_dir, \"yolo_dataset_1024\")\n",
    "\n",
    "    # Create output directories\n",
    "    if map_folder == validation_set:\n",
    "        img_out = os.path.join(out_base, \"images\", \"val\")\n",
    "        lbl_out = os.path.join(out_base, \"labels\", \"val\")\n",
    "    else:\n",
    "        img_out = os.path.join(out_base, \"images\", \"train\")\n",
    "        lbl_out = os.path.join(out_base, \"labels\", \"train\")\n",
    "    \n",
    "    os.makedirs(img_out, exist_ok=True)\n",
    "    os.makedirs(lbl_out, exist_ok=True)\n",
    "\n",
    "    # Process all files\n",
    "    counts = {\"labeled\": 0, \"background\": 0, \"error\": 0}\n",
    "    chip_files = [f for f in os.listdir(img_input_dir) if f.endswith(\".png\")]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(process_file, f, img_input_dir, mask_input_dir, img_out, lbl_out) for f in chip_files]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=f\"{map_folder}\"):\n",
    "            result = f.result()\n",
    "            counts[result] += 1\n",
    "\n",
    "    print(f\"‚úÖ {map_folder} summary:\")\n",
    "    print(f\"   - {counts['labeled']} labeled tiles\")\n",
    "    print(f\"   - {counts['background']} background-only tiles\")\n",
    "    print(f\"   - {counts['error']} errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6adadb50-6f71-4253-9a3f-2062fc05f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying datasets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged datasets into: /home/znelson/TensorStream/Labeled Data/dataset (excluding background-only tiles)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NEW DATASET BUILDER EXCLUDES BACKGROUND CHIPS\n",
    "# -----------------------------------------------------------\n",
    "# üì¶ Unified YOLO Dataset Builder (Excludes Holdout Set)\n",
    "#\n",
    "# This script merges YOLO-formatted image and label tiles from\n",
    "# multiple map sets into a single unified dataset structure.\n",
    "#\n",
    "# Excludes holdout map: Flight_2_25pct\n",
    "# Output folders:\n",
    "# - dataset/images/train/\n",
    "# - dataset/images/val/\n",
    "# - dataset/labels/train/\n",
    "# - dataset/labels/val/\n",
    "# - dataset/manifests/train_files.txt and val_files.txt\n",
    "# -----------------------------------------------------------\n",
    "# path: /home/znelson/TensorStream/Labeled Data/dataset\n",
    "# train: images/train\n",
    "# val: images/val\n",
    "# nc: 4\n",
    "# names: [\"Background\", \"Road\", \"PVeg\", \"Water\"]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/\"\n",
    "dataset_dir = os.path.join(base_dir, \"dataset\")\n",
    "img_train_dir = os.path.join(dataset_dir, \"images\", \"train\")\n",
    "img_val_dir = os.path.join(dataset_dir, \"images\", \"val\")\n",
    "lbl_train_dir = os.path.join(dataset_dir, \"labels\", \"train\")\n",
    "lbl_val_dir = os.path.join(dataset_dir, \"labels\", \"val\")\n",
    "\n",
    "validation_set = \"Flight_2\"\n",
    "exclude_set = \"Flight_2_25pct\"\n",
    "\n",
    "all_sets = [\n",
    "    \"Bear_Creek_20250112\",\n",
    "    \"Bear_Lane\",\n",
    "    \"Flight_2\",\n",
    "    \"SFLBC\",\n",
    "    \"Sugar_Refugia_20241112\",\n",
    "    \"Wildcat_Creek\",\n",
    "    \"Project_2024_09_20\"\n",
    "]\n",
    "\n",
    "# --- Create necessary directories ---\n",
    "for d in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# --- Clean old contents ---\n",
    "for folder in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
    "    for f in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, f)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "# --- Copy pre-sorted train/val files from each set ---\n",
    "for set_name in tqdm(all_sets, desc=\"Copying datasets\"):\n",
    "    if set_name == exclude_set:\n",
    "        print(f\"‚è≠Ô∏è Skipping excluded set: {exclude_set}\")\n",
    "        continue\n",
    "\n",
    "    base_map_dir = os.path.join(base_dir, set_name, \"yolo_dataset_1024\")\n",
    "    for mode in [\"train\", \"val\"]:\n",
    "        img_src_dir = os.path.join(base_map_dir, \"images\", mode)\n",
    "        lbl_src_dir = os.path.join(base_map_dir, \"labels\", mode)\n",
    "\n",
    "        if not os.path.exists(img_src_dir) or not os.path.exists(lbl_src_dir):\n",
    "            continue\n",
    "\n",
    "        if set_name == validation_set:\n",
    "            img_dst_dir = img_val_dir\n",
    "            lbl_dst_dir = lbl_val_dir\n",
    "        else:\n",
    "            img_dst_dir = img_train_dir\n",
    "            lbl_dst_dir = lbl_train_dir\n",
    "\n",
    "        for img_file in os.listdir(img_src_dir):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                label_file = img_file.replace(\".png\", \".txt\")\n",
    "                lbl_src = os.path.join(lbl_src_dir, label_file)\n",
    "\n",
    "                # Skip background-only tiles\n",
    "                if not os.path.exists(lbl_src) or os.path.getsize(lbl_src) == 0:\n",
    "                    continue\n",
    "\n",
    "                prefix = set_name + \"_\"\n",
    "                img_dst = os.path.join(img_dst_dir, prefix + img_file)\n",
    "                lbl_dst = os.path.join(lbl_dst_dir, prefix + label_file)\n",
    "\n",
    "                shutil.copy(os.path.join(img_src_dir, img_file), img_dst)\n",
    "                shutil.copy(lbl_src, lbl_dst)\n",
    "\n",
    "print(f\"‚úÖ Merged datasets into: {dataset_dir} (excluding background-only tiles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d6af75-7850-4ec9-be92-d615cecf3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying datasets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 7935.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged datasets into: /home/znelson/TensorStream/Labeled Data/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# üì¶ Unified YOLO Dataset Builder (Excludes Holdout Set)\n",
    "#\n",
    "# This script merges YOLO-formatted image and label tiles from\n",
    "# multiple map sets into a single unified dataset structure.\n",
    "#\n",
    "# Excludes holdout map: Flight_2_25pct\n",
    "# Output folders:\n",
    "# - dataset/images/train/\n",
    "# - dataset/images/val/\n",
    "# - dataset/labels/train/\n",
    "# - dataset/labels/val/\n",
    "# - dataset/manifests/train_files.txt and val_files.txt\n",
    "# -----------------------------------------------------------\n",
    "# path: /home/znelson/TensorStream/Labeled Data/dataset\n",
    "# train: images/train\n",
    "# val: images/val\n",
    "# nc: 4\n",
    "# names: [\"Background\", \"Road\", \"PVeg\", \"Water\"]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/\"\n",
    "dataset_dir = os.path.join(base_dir, \"dataset\")\n",
    "img_train_dir = os.path.join(dataset_dir, \"images\", \"train\")\n",
    "img_val_dir = os.path.join(dataset_dir, \"images\", \"val\")\n",
    "lbl_train_dir = os.path.join(dataset_dir, \"labels\", \"train\")\n",
    "lbl_val_dir = os.path.join(dataset_dir, \"labels\", \"val\")\n",
    "\n",
    "validation_set = \"Flight_2\"\n",
    "exclude_set = \"Flight_2_25pct\"\n",
    "\n",
    "all_sets = [\n",
    "    \"Bear_Creek_20250112\",\n",
    "    \"Bear_Lane\",\n",
    "    \"Flight_2\",\n",
    "    \"SFLBC\",\n",
    "    \"Sugar_Refugia_20241112\",\n",
    "    \"Wildcat_Creek\",\n",
    "    \"Project_2024_09_20\"\n",
    "]\n",
    "\n",
    "# --- Create necessary directories ---\n",
    "for d in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# --- Clean old contents ---\n",
    "for folder in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
    "    for f in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, f)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "# --- Copy pre-sorted train/val files from each set ---\n",
    "for set_name in tqdm(all_sets, desc=\"Copying datasets\"):\n",
    "    # Skip the excluded set\n",
    "    if set_name == exclude_set:\n",
    "        print(f\"‚è≠Ô∏è Skipping excluded set: {exclude_set}\")\n",
    "        continue\n",
    "\n",
    "    base_map_dir = os.path.join(base_dir, set_name, \"yolo_dataset_640\")\n",
    "    for mode in [\"train\", \"val\"]:\n",
    "        img_src_dir = os.path.join(base_map_dir, \"images\", mode)\n",
    "        lbl_src_dir = os.path.join(base_map_dir, \"labels\", mode)\n",
    "\n",
    "        if not os.path.exists(img_src_dir) or not os.path.exists(lbl_src_dir):\n",
    "            continue\n",
    "\n",
    "        # Determine output directories\n",
    "        if set_name == validation_set:\n",
    "            img_dst_dir = img_val_dir\n",
    "            lbl_dst_dir = lbl_val_dir\n",
    "        else:\n",
    "            img_dst_dir = img_train_dir\n",
    "            lbl_dst_dir = lbl_train_dir\n",
    "\n",
    "        # Copy images and labels with prefix\n",
    "        for img_file in os.listdir(img_src_dir):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                prefix = set_name + \"_\"\n",
    "                img_dst = os.path.join(img_dst_dir, prefix + img_file)\n",
    "                lbl_dst = os.path.join(lbl_dst_dir, prefix + img_file.replace(\".png\", \".txt\"))\n",
    "\n",
    "                # Copy image\n",
    "                shutil.copy(os.path.join(img_src_dir, img_file), img_dst)\n",
    "\n",
    "                # Copy label\n",
    "                lbl_src = os.path.join(lbl_src_dir, img_file.replace(\".png\", \".txt\"))\n",
    "                if os.path.exists(lbl_src):\n",
    "                    shutil.copy(lbl_src, lbl_dst)\n",
    "                else:\n",
    "                    open(lbl_dst, \"w\").close()\n",
    "\n",
    "print(f\"‚úÖ Merged datasets into: {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a57d85d-a180-41e1-917f-209b993ed2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ac9ede-d4ca-4b13-9873-4cca830c45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697b6861-98bd-49ce-9e34-c8b720291f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d3f093-8999-4df9-abbe-ab00c2ac49ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 2\n",
      "Device Name: NVIDIA GeForce RTX 2080 Ti\n",
      "Current Device: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(1))\n",
    "    print(\"Current Device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a4582-3094-4834-8476-49b12c160f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size Memory Test Script\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# Config\n",
    "imgsz = 640\n",
    "data_yaml = \"/home/znelson/TensorStream/Labeled Data/dataset/data.yaml\"\n",
    "\n",
    "# Sweep from small to large batch sizes\n",
    "#for batch in [3, 4, 6, 8, 10, 12]:\n",
    "#for batch in [4, 8, 12, 16, 20, 24, 32]:\n",
    "for batch in [32, 48, 64]:\n",
    "#for batch in [16, 20, 24, 32]:\n",
    "    print(f\"\\nüöÄ Testing batch size: {batch}\")\n",
    "    try:\n",
    "        model.train(\n",
    "            data=data_yaml,\n",
    "            imgsz=imgsz,\n",
    "            epochs=1,           # just one epoch for testing\n",
    "            batch=batch,\n",
    "            device=\"0\",\n",
    "            workers=2,          # keep this low to minimize RAM pressure\n",
    "            cache=\"ram\",\n",
    "            amp=True,\n",
    "            verbose=False,\n",
    "            plots=False\n",
    "        )\n",
    "        print(f\"‚úÖ Batch size {batch} succeeded.\")\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(f\"‚ùå OOM at batch size {batch}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            break\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede382b-720a-4782-87e1-85d52bfb2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW MODEL REPORT\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --- Paths ---\n",
    "results_path = f\"/home/znelson/TensorStream/Labeled Data/runs/segment/train/yolov8s_1600to1024_model01/results.csv\"\n",
    "report_path = f\"/home/znelson/TensorStream/Labeled Data/diagnostics/yolov8s_1600to1024_model01.pdf\"\n",
    "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "# --- Load results and clean columns ---\n",
    "df = pd.read_csv(results_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# --- Calculate F1-score ---\n",
    "df['metrics/f1(B)'] = 2 * (df['metrics/precision(B)'] * df['metrics/recall(B)']) / (\n",
    "    df['metrics/precision(B)'] + df['metrics/recall(B)']).replace(0, 1e-8)\n",
    "\n",
    "# --- Key epoch metrics ---\n",
    "final_epoch = df.iloc[-1]\n",
    "best_map_epoch = df[\"metrics/mAP50(B)\"].idxmax()\n",
    "best_row = df.iloc[best_map_epoch]\n",
    "\n",
    "# --- Basic training config (update if needed) ---\n",
    "training_config = {\n",
    "    \"Model\": \"YOLOv8s-seg\",\n",
    "    \"Input Size\": \"1024x1024\",\n",
    "    \"Epochs\": len(df),\n",
    "    \"Batch Size\": 12,\n",
    "    \"Optimizer\": \"AdamW\",\n",
    "    \"Confidence Threshold\": 0.1,\n",
    "    \"Tile Size\": \"1600x1600 (20% overlap stride: 1280x1280)\",\n",
    "    \"Mask Source\": \"Polygon label ‚Üí Raster mask via cv2.fillPoly\"\n",
    "}\n",
    "\n",
    "# --- Metrics to plot ---\n",
    "metrics = {\n",
    "    \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(B)\": \"mAP@0.5‚Äì095\",\n",
    "    \"metrics/precision(B)\": \"Precision\",\n",
    "    \"metrics/recall(B)\": \"Recall\",\n",
    "    \"metrics/f1(B)\": \"F1 Score\"\n",
    "}\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "# --- Create PDF report ---\n",
    "with PdfPages(report_path) as pdf:\n",
    "    # Title + Summary page\n",
    "    plt.figure(figsize=(11, 8.5))\n",
    "    plt.text(0.5, 0.78, \"Model Performance Report\", ha=\"center\", fontsize=24)\n",
    "    plt.text(0.5, 0.70, \"Project: River and Road Segmentation\", ha=\"center\", fontsize=14)\n",
    "    plt.text(0.5, 0.63, f\"Best mAP@0.5: {best_row['metrics/mAP50(B)']:.3f} at epoch {best_map_epoch}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.57, f\"Final Epoch Precision: {final_epoch['metrics/precision(B)']:.3f}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.51, f\"Final Epoch Recall: {final_epoch['metrics/recall(B)']:.3f}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.45, f\"Final Epoch F1 Score: {final_epoch['metrics/f1(B)']:.3f}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.39, \"Report generated from YOLOv8s results.csv\", ha=\"center\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Training configuration page\n",
    "    fig, ax = plt.subplots(figsize=(11, 4))\n",
    "    ax.axis(\"off\")\n",
    "    table_data = list(training_config.items())\n",
    "    table = ax.table(cellText=table_data, colLabels=[\"Parameter\", \"Value\"], loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1.2, 1.4)\n",
    "    plt.title(\"Training Configuration\", fontsize=14)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Metric plots\n",
    "    for i, (key, label) in enumerate(metrics.items()):\n",
    "        if key in df.columns:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(df[key], marker='o', linewidth=2, color=colors[i % len(colors)])\n",
    "            plt.title(f\"{label} Over Epochs\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(label)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "    # Performance summary table\n",
    "    summary_data = {\n",
    "        \"Metric\": [\"mAP@0.5\", \"mAP@0.5‚Äì095\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
    "        \"Final Epoch\": [\n",
    "            f\"{final_epoch.get('metrics/mAP50(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/mAP50-95(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/precision(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/recall(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/f1(B)', 0):.3f}\"\n",
    "        ],\n",
    "        f\"Best Epoch ({best_map_epoch})\": [\n",
    "            f\"{best_row.get('metrics/mAP50(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/mAP50-95(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/precision(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/recall(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/f1(B)', 0):.3f}\"\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.8))\n",
    "    ax.axis(\"off\")\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.8)\n",
    "    plt.title(\"Summary of Model Performance\", fontsize=14)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"‚úÖ PDF report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d360cd-8075-4e5f-ba36-1b47253c6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2dd760-14d6-4078-b026-015fdb187779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF report saved to: /home/znelson/TensorStream/Labeled Data/diagnostics/yolov8n_1024to640_model02.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --- Paths ---\n",
    "results_path = f\"/home/znelson/TensorStream/Labeled Data/runs/segment/train/yolov8s_1600to1024_model01/results.csv\"\n",
    "report_path = f\"/home/znelson/TensorStream/Labeled Data/diagnostics/yolov8s_1600to1024_model01.pdf\"\n",
    "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "# --- Load results and clean columns ---\n",
    "df = pd.read_csv(results_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# --- Key epoch metrics ---\n",
    "final_epoch = df.iloc[-1]\n",
    "best_map_epoch = df[\"metrics/mAP50(B)\"].idxmax()\n",
    "best_row = df.iloc[best_map_epoch]\n",
    "\n",
    "# --- Basic training config (update if needed) ---\n",
    "training_config = {\n",
    "    \"Model\": \"YOLOv8s-seg\",\n",
    "    \"Input Size\": \"1024x1024\",\n",
    "    \"Epochs\": len(df),\n",
    "    \"Batch Size\": 12,\n",
    "    \"Optimizer\": \"AdamW\",\n",
    "    \"Confidence Threshold\": 0.1,\n",
    "    \"Tile Size\": \"1600x1600 (20%\\ overlap stride: 1280x1280)\",\n",
    "    \"Mask Source\": \"Polygon label ‚Üí Raster mask via cv2.fillPoly\"\n",
    "}\n",
    "\n",
    "# --- Metrics to plot ---\n",
    "metrics = {\n",
    "    \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(B)\": \"mAP@0.5‚Äì0.95\",\n",
    "    \"metrics/precision(B)\": \"Precision\",\n",
    "    \"metrics/recall(B)\": \"Recall\"\n",
    "}\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "\n",
    "# --- Create PDF report ---\n",
    "with PdfPages(report_path) as pdf:\n",
    "    # Title + Summary page\n",
    "    plt.figure(figsize=(11, 8.5))\n",
    "    plt.text(0.5, 0.78, \"Model Performance Report\", ha=\"center\", fontsize=24)\n",
    "    plt.text(0.5, 0.70, \"Project: River and Road Segmentation\", ha=\"center\", fontsize=14)\n",
    "    plt.text(0.5, 0.63, f\"Best mAP@0.5: {best_row['metrics/mAP50(B)']:.3f} at epoch {best_map_epoch}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.57, f\"Final Epoch Precision: {final_epoch['metrics/precision(B)']:.3f}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.51, f\"Final Epoch Recall: {final_epoch['metrics/recall(B)']:.3f}\", ha=\"center\", fontsize=12)\n",
    "    plt.text(0.5, 0.45, \"Report generated from YOLOv8s results.csv\", ha=\"center\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Training configuration page\n",
    "    fig, ax = plt.subplots(figsize=(11, 4))\n",
    "    ax.axis(\"off\")\n",
    "    table_data = list(training_config.items())\n",
    "    table = ax.table(cellText=table_data, colLabels=[\"Parameter\", \"Value\"], loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1.2, 1.4)\n",
    "    plt.title(\"Training Configuration\", fontsize=14)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Metric plots\n",
    "    for i, (key, label) in enumerate(metrics.items()):\n",
    "        if key in df.columns:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(df[key], marker='o', linewidth=2, color=colors[i])\n",
    "            plt.title(f\"{label} Over Epochs\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(label)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "    # Performance summary table\n",
    "    summary_data = {\n",
    "        \"Metric\": [\"mAP@0.5\", \"mAP@0.5‚Äì0.95\", \"Precision\", \"Recall\"],\n",
    "        \"Final Epoch\": [\n",
    "            f\"{final_epoch.get('metrics/mAP50(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/mAP50-95(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/precision(B)', 0):.3f}\",\n",
    "            f\"{final_epoch.get('metrics/recall(B)', 0):.3f}\"\n",
    "        ],\n",
    "        f\"Best Epoch ({best_map_epoch})\": [\n",
    "            f\"{best_row.get('metrics/mAP50(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/mAP50-95(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/precision(B)', 0):.3f}\",\n",
    "            f\"{best_row.get('metrics/recall(B)', 0):.3f}\"\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.5))\n",
    "    ax.axis(\"off\")\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.8)\n",
    "    plt.title(\"Summary of Model Performance\", fontsize=14)\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"‚úÖ PDF report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9ad04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleared 235 old prediction files from: /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/predictions/predict_txt/labels\n",
      "\n",
      "image 1/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_103.png: 640x640 1 PVeg, 5.1ms\n",
      "image 2/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_104.png: 640x640 1 Road, 4 PVegs, 5.4ms\n",
      "image 3/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_105.png: 640x640 1 Road, 3 PVegs, 5.0ms\n",
      "image 4/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_106.png: 640x640 3 PVegs, 5.0ms\n",
      "image 5/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_107.png: 640x640 4 PVegs, 5.0ms\n",
      "image 6/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_108.png: 640x640 6 PVegs, 5.0ms\n",
      "image 7/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_109.png: 640x640 17 PVegs, 5.0ms\n",
      "image 8/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_110.png: 640x640 22 PVegs, 5.6ms\n",
      "image 9/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_111.png: 640x640 16 PVegs, 5.7ms\n",
      "image 10/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_112.png: 640x640 8 PVegs, 5.6ms\n",
      "image 11/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_113.png: 640x640 5 PVegs, 5.4ms\n",
      "image 12/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_114.png: 640x640 6 PVegs, 1 Water, 5.1ms\n",
      "image 13/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_115.png: 640x640 8 PVegs, 5.8ms\n",
      "image 14/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_130.png: 640x640 (no detections), 5.0ms\n",
      "image 15/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_131.png: 640x640 2 Roads, 5.0ms\n",
      "image 16/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_132.png: 640x640 2 Roads, 12 PVegs, 5.1ms\n",
      "image 17/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_133.png: 640x640 1 Road, 5 PVegs, 5.8ms\n",
      "image 18/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_134.png: 640x640 2 PVegs, 5.1ms\n",
      "image 19/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_135.png: 640x640 6 PVegs, 5.2ms\n",
      "image 20/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_136.png: 640x640 13 PVegs, 5.6ms\n",
      "image 21/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_137.png: 640x640 9 PVegs, 5.1ms\n",
      "image 22/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_138.png: 640x640 8 PVegs, 5.0ms\n",
      "image 23/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_139.png: 640x640 8 PVegs, 5.7ms\n",
      "image 24/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_140.png: 640x640 10 PVegs, 5.0ms\n",
      "image 25/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_141.png: 640x640 16 PVegs, 5.0ms\n",
      "image 26/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_142.png: 640x640 11 PVegs, 5.7ms\n",
      "image 27/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_143.png: 640x640 4 PVegs, 4 Waters, 5.1ms\n",
      "image 28/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_144.png: 640x640 8 PVegs, 5.0ms\n",
      "image 29/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_158.png: 640x640 1 Road, 2 PVegs, 5.1ms\n",
      "image 30/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_159.png: 640x640 2 Roads, 9 PVegs, 5.0ms\n",
      "image 31/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_160.png: 640x640 1 Road, 8 PVegs, 5.1ms\n",
      "image 32/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_161.png: 640x640 5 Roads, 13 PVegs, 5.6ms\n",
      "image 33/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_162.png: 640x640 21 PVegs, 5.2ms\n",
      "image 34/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_163.png: 640x640 13 PVegs, 5.0ms\n",
      "image 35/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_164.png: 640x640 15 PVegs, 5.3ms\n",
      "image 36/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_165.png: 640x640 10 PVegs, 5.0ms\n",
      "image 37/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_166.png: 640x640 10 PVegs, 5.7ms\n",
      "image 38/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_167.png: 640x640 19 PVegs, 5.7ms\n",
      "image 39/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_168.png: 640x640 23 PVegs, 5.0ms\n",
      "image 40/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_169.png: 640x640 27 PVegs, 5.0ms\n",
      "image 41/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_170.png: 640x640 27 PVegs, 5.4ms\n",
      "image 42/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_171.png: 640x640 21 PVegs, 5.0ms\n",
      "image 43/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_172.png: 640x640 13 PVegs, 5.8ms\n",
      "image 44/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_173.png: 640x640 3 PVegs, 5.0ms\n",
      "image 45/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_185.png: 640x640 (no detections), 4.9ms\n",
      "image 46/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_186.png: 640x640 1 Road, 5 PVegs, 4.8ms\n",
      "image 47/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_187.png: 640x640 14 PVegs, 5.6ms\n",
      "image 48/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_188.png: 640x640 13 PVegs, 4.9ms\n",
      "image 49/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_189.png: 640x640 4 PVegs, 5.6ms\n",
      "image 50/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_190.png: 640x640 13 PVegs, 5.5ms\n",
      "image 51/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_191.png: 640x640 9 PVegs, 5.6ms\n",
      "image 52/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_192.png: 640x640 9 PVegs, 5.6ms\n",
      "image 53/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_193.png: 640x640 16 PVegs, 5.6ms\n",
      "image 54/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_194.png: 640x640 15 PVegs, 5.6ms\n",
      "image 55/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_195.png: 640x640 10 PVegs, 5.7ms\n",
      "image 56/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_196.png: 640x640 13 PVegs, 8.4ms\n",
      "image 57/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_197.png: 640x640 20 PVegs, 5.7ms\n",
      "image 58/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_198.png: 640x640 38 PVegs, 5.1ms\n",
      "image 59/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_199.png: 640x640 26 PVegs, 5.7ms\n",
      "image 60/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_200.png: 640x640 15 PVegs, 5.0ms\n",
      "image 61/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_201.png: 640x640 2 PVegs, 4.9ms\n",
      "image 62/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_213.png: 640x640 2 PVegs, 5.0ms\n",
      "image 63/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_214.png: 640x640 1 Road, 9 PVegs, 5.0ms\n",
      "image 64/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_215.png: 640x640 1 Road, 7 PVegs, 4.9ms\n",
      "image 65/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_216.png: 640x640 9 PVegs, 5.6ms\n",
      "image 66/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_217.png: 640x640 13 PVegs, 5.6ms\n",
      "image 67/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_218.png: 640x640 18 PVegs, 4.9ms\n",
      "image 68/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_219.png: 640x640 14 PVegs, 5.6ms\n",
      "image 69/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_220.png: 640x640 10 PVegs, 5.6ms\n",
      "image 70/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_221.png: 640x640 20 PVegs, 4.9ms\n",
      "image 71/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_222.png: 640x640 19 PVegs, 5.6ms\n",
      "image 72/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_223.png: 640x640 22 PVegs, 5.6ms\n",
      "image 73/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_224.png: 640x640 20 PVegs, 5.0ms\n",
      "image 74/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_225.png: 640x640 21 PVegs, 5.0ms\n",
      "image 75/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_226.png: 640x640 20 PVegs, 12.5ms\n",
      "image 76/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_227.png: 640x640 6 PVegs, 6.8ms\n",
      "image 77/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_228.png: 640x640 (no detections), 5.0ms\n",
      "image 78/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_23.png: 640x640 (no detections), 5.1ms\n",
      "image 79/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_24.png: 640x640 (no detections), 4.9ms\n",
      "image 80/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_241.png: 640x640 2 PVegs, 5.0ms\n",
      "image 81/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_242.png: 640x640 1 Road, 3 PVegs, 5.2ms\n",
      "image 82/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_243.png: 640x640 1 Road, 8 PVegs, 5.4ms\n",
      "image 83/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_244.png: 640x640 6 PVegs, 5.0ms\n",
      "image 84/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_245.png: 640x640 21 PVegs, 5.0ms\n",
      "image 85/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_246.png: 640x640 14 PVegs, 5.6ms\n",
      "image 86/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_247.png: 640x640 9 PVegs, 5.2ms\n",
      "image 87/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_248.png: 640x640 8 PVegs, 5.6ms\n",
      "image 88/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_249.png: 640x640 9 PVegs, 5.0ms\n",
      "image 89/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_25.png: 640x640 9 PVegs, 5.0ms\n",
      "image 90/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_250.png: 640x640 20 PVegs, 5.1ms\n",
      "image 91/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_251.png: 640x640 39 PVegs, 5.6ms\n",
      "image 92/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_252.png: 640x640 30 PVegs, 4.9ms\n",
      "image 93/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_253.png: 640x640 9 PVegs, 4.9ms\n",
      "image 94/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_254.png: 640x640 4 PVegs, 5.0ms\n",
      "image 95/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_26.png: 640x640 11 PVegs, 5.7ms\n",
      "image 96/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_269.png: 640x640 1 PVeg, 5.0ms\n",
      "image 97/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_27.png: 640x640 6 PVegs, 5.1ms\n",
      "image 98/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_270.png: 640x640 1 Road, 4 PVegs, 5.6ms\n",
      "image 99/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_271.png: 640x640 1 Road, 5 PVegs, 5.6ms\n",
      "image 100/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_272.png: 640x640 9 PVegs, 5.5ms\n",
      "image 101/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_273.png: 640x640 20 PVegs, 5.6ms\n",
      "image 102/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_274.png: 640x640 6 PVegs, 5.7ms\n",
      "image 103/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_275.png: 640x640 14 PVegs, 5.0ms\n",
      "image 104/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_276.png: 640x640 11 PVegs, 4.9ms\n",
      "image 105/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_277.png: 640x640 15 PVegs, 4.9ms\n",
      "image 106/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_278.png: 640x640 24 PVegs, 4.9ms\n",
      "image 107/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_279.png: 640x640 26 PVegs, 5.2ms\n",
      "image 108/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_280.png: 640x640 5 PVegs, 5.1ms\n",
      "image 109/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_281.png: 640x640 3 PVegs, 5.0ms\n",
      "image 110/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_297.png: 640x640 (no detections), 5.0ms\n",
      "image 111/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_298.png: 640x640 1 Road, 6 PVegs, 4.9ms\n",
      "image 112/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_299.png: 640x640 1 Road, 7 PVegs, 5.6ms\n",
      "image 113/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_300.png: 640x640 6 PVegs, 5.0ms\n",
      "image 114/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_301.png: 640x640 18 PVegs, 5.6ms\n",
      "image 115/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_302.png: 640x640 20 PVegs, 5.6ms\n",
      "image 116/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_303.png: 640x640 16 PVegs, 5.6ms\n",
      "image 117/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_304.png: 640x640 33 PVegs, 5.7ms\n",
      "image 118/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_305.png: 640x640 13 PVegs, 5.5ms\n",
      "image 119/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_306.png: 640x640 15 PVegs, 5.6ms\n",
      "image 120/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_307.png: 640x640 16 PVegs, 5.0ms\n",
      "image 121/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_308.png: 640x640 3 PVegs, 5.2ms\n",
      "image 122/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_325.png: 640x640 2 PVegs, 5.0ms\n",
      "image 123/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_326.png: 640x640 2 Roads, 4.9ms\n",
      "image 124/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_327.png: 640x640 1 Road, 8 PVegs, 5.0ms\n",
      "image 125/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_328.png: 640x640 13 PVegs, 5.0ms\n",
      "image 126/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_329.png: 640x640 13 PVegs, 5.6ms\n",
      "image 127/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_330.png: 640x640 18 PVegs, 5.7ms\n",
      "image 128/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_331.png: 640x640 24 PVegs, 5.6ms\n",
      "image 129/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_332.png: 640x640 21 PVegs, 5.6ms\n",
      "image 130/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_333.png: 640x640 20 PVegs, 5.7ms\n",
      "image 131/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_334.png: 640x640 23 PVegs, 5.0ms\n",
      "image 132/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_335.png: 640x640 4 PVegs, 4.9ms\n",
      "image 133/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_353.png: 640x640 1 PVeg, 4.9ms\n",
      "image 134/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_354.png: 640x640 1 Road, 5 PVegs, 4.9ms\n",
      "image 135/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_355.png: 640x640 1 Road, 10 PVegs, 5.1ms\n",
      "image 136/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_356.png: 640x640 11 PVegs, 5.6ms\n",
      "image 137/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_357.png: 640x640 13 PVegs, 5.6ms\n",
      "image 138/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_358.png: 640x640 14 PVegs, 5.6ms\n",
      "image 139/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_359.png: 640x640 11 PVegs, 5.0ms\n",
      "image 140/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_360.png: 640x640 16 PVegs, 5.2ms\n",
      "image 141/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_361.png: 640x640 17 PVegs, 5.7ms\n",
      "image 142/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_362.png: 640x640 12 PVegs, 5.1ms\n",
      "image 143/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_363.png: 640x640 1 PVeg, 5.1ms\n",
      "image 144/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_381.png: 640x640 1 PVeg, 4.9ms\n",
      "image 145/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_382.png: 640x640 1 Road, 12 PVegs, 12.0ms\n",
      "image 146/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_383.png: 640x640 1 Road, 15 PVegs, 5.6ms\n",
      "image 147/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_384.png: 640x640 5 Roads, 18 PVegs, 5.6ms\n",
      "image 148/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_385.png: 640x640 17 PVegs, 4.9ms\n",
      "image 149/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_386.png: 640x640 16 PVegs, 1 Water, 5.6ms\n",
      "image 150/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_387.png: 640x640 12 PVegs, 4.9ms\n",
      "image 151/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_388.png: 640x640 9 PVegs, 5.1ms\n",
      "image 152/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_389.png: 640x640 17 PVegs, 5.6ms\n",
      "image 153/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_390.png: 640x640 7 PVegs, 5.1ms\n",
      "image 154/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_391.png: 640x640 1 PVeg, 5.3ms\n",
      "image 155/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_409.png: 640x640 (no detections), 5.2ms\n",
      "image 156/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_410.png: 640x640 1 Road, 10 PVegs, 5.0ms\n",
      "image 157/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_411.png: 640x640 1 Road, 13 PVegs, 4.9ms\n",
      "image 158/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_412.png: 640x640 3 Roads, 11 PVegs, 4.9ms\n",
      "image 159/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_413.png: 640x640 16 PVegs, 1 Water, 5.6ms\n",
      "image 160/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_414.png: 640x640 26 PVegs, 5.6ms\n",
      "image 161/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_415.png: 640x640 18 PVegs, 5.0ms\n",
      "image 162/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_416.png: 640x640 4 PVegs, 5.0ms\n",
      "image 163/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_417.png: 640x640 23 PVegs, 5.0ms\n",
      "image 164/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_418.png: 640x640 17 PVegs, 4.9ms\n",
      "image 165/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_419.png: 640x640 (no detections), 7.9ms\n",
      "image 166/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_437.png: 640x640 2 PVegs, 4.9ms\n",
      "image 167/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_438.png: 640x640 2 Roads, 12 PVegs, 5.6ms\n",
      "image 168/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_439.png: 640x640 1 Road, 13 PVegs, 5.6ms\n",
      "image 169/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_440.png: 640x640 13 PVegs, 5.8ms\n",
      "image 170/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_441.png: 640x640 15 PVegs, 5.6ms\n",
      "image 171/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_442.png: 640x640 10 PVegs, 1 Water, 5.0ms\n",
      "image 172/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_443.png: 640x640 7 PVegs, 5.7ms\n",
      "image 173/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_444.png: 640x640 7 PVegs, 5.0ms\n",
      "image 174/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_445.png: 640x640 11 PVegs, 5.6ms\n",
      "image 175/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_446.png: 640x640 17 PVegs, 5.2ms\n",
      "image 176/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_447.png: 640x640 2 PVegs, 5.3ms\n",
      "image 177/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_465.png: 640x640 (no detections), 4.9ms\n",
      "image 178/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_466.png: 640x640 1 Road, 11 PVegs, 4.9ms\n",
      "image 179/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_467.png: 640x640 2 Roads, 17 PVegs, 5.7ms\n",
      "image 180/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_468.png: 640x640 19 PVegs, 4.9ms\n",
      "image 181/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_469.png: 640x640 7 PVegs, 1 Water, 5.6ms\n",
      "image 182/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_470.png: 640x640 8 PVegs, 2 Waters, 5.2ms\n",
      "image 183/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_471.png: 640x640 23 PVegs, 1 Water, 4.9ms\n",
      "image 184/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_472.png: 640x640 3 PVegs, 4.9ms\n",
      "image 185/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_473.png: 640x640 14 PVegs, 5.6ms\n",
      "image 186/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_474.png: 640x640 12 PVegs, 5.6ms\n",
      "image 187/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_494.png: 640x640 1 Road, 5 PVegs, 5.4ms\n",
      "image 188/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_495.png: 640x640 2 Roads, 9 PVegs, 5.3ms\n",
      "image 189/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_496.png: 640x640 12 PVegs, 5.7ms\n",
      "image 190/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_497.png: 640x640 8 PVegs, 2 Waters, 5.7ms\n",
      "image 191/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_498.png: 640x640 6 PVegs, 5.8ms\n",
      "image 192/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_499.png: 640x640 19 PVegs, 5.7ms\n",
      "image 193/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_50.png: 640x640 1 PVeg, 5.0ms\n",
      "image 194/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_500.png: 640x640 11 PVegs, 4.9ms\n",
      "image 195/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_501.png: 640x640 9 PVegs, 5.7ms\n",
      "image 196/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_502.png: 640x640 10 PVegs, 5.6ms\n",
      "image 197/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_503.png: 640x640 3 PVegs, 5.2ms\n",
      "image 198/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_51.png: 640x640 6 PVegs, 5.2ms\n",
      "image 199/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_52.png: 640x640 1 PVeg, 5.6ms\n",
      "image 200/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_522.png: 640x640 1 Road, 1 PVeg, 5.0ms\n",
      "image 201/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_523.png: 640x640 1 Road, 14 PVegs, 5.1ms\n",
      "image 202/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_524.png: 640x640 23 PVegs, 5.7ms\n",
      "image 203/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_525.png: 640x640 10 PVegs, 1 Water, 5.6ms\n",
      "image 204/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_526.png: 640x640 6 PVegs, 3 Waters, 5.6ms\n",
      "image 205/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_527.png: 640x640 18 PVegs, 5.0ms\n",
      "image 206/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_528.png: 640x640 15 PVegs, 5.0ms\n",
      "image 207/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_529.png: 640x640 15 PVegs, 5.4ms\n",
      "image 208/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_53.png: 640x640 7 PVegs, 5.6ms\n",
      "image 209/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_530.png: 640x640 14 PVegs, 5.4ms\n",
      "image 210/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_531.png: 640x640 (no detections), 5.1ms\n",
      "image 211/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_54.png: 640x640 23 PVegs, 5.0ms\n",
      "image 212/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_55.png: 640x640 19 PVegs, 5.2ms\n",
      "image 213/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_551.png: 640x640 1 Road, 7 PVegs, 5.1ms\n",
      "image 214/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_552.png: 640x640 19 PVegs, 5.0ms\n",
      "image 215/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_553.png: 640x640 22 PVegs, 5.0ms\n",
      "image 216/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_554.png: 640x640 11 PVegs, 1 Water, 5.2ms\n",
      "image 217/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_555.png: 640x640 21 PVegs, 5.2ms\n",
      "image 218/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_556.png: 640x640 22 PVegs, 5.1ms\n",
      "image 219/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_557.png: 640x640 7 PVegs, 5.1ms\n",
      "image 220/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_558.png: 640x640 13 PVegs, 5.7ms\n",
      "image 221/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_559.png: 640x640 1 PVeg, 5.4ms\n",
      "image 222/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_56.png: 640x640 9 PVegs, 5.2ms\n",
      "image 223/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_57.png: 640x640 (no detections), 5.0ms\n",
      "image 224/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_580.png: 640x640 10 PVegs, 4.9ms\n",
      "image 225/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_581.png: 640x640 22 PVegs, 5.6ms\n",
      "image 226/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_582.png: 640x640 14 PVegs, 5.7ms\n",
      "image 227/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_583.png: 640x640 17 PVegs, 3 Waters, 5.1ms\n",
      "image 228/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_584.png: 640x640 19 PVegs, 5.7ms\n",
      "image 229/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_585.png: 640x640 14 PVegs, 5.2ms\n",
      "image 230/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_586.png: 640x640 13 PVegs, 5.6ms\n",
      "image 231/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_587.png: 640x640 1 PVeg, 5.1ms\n",
      "image 232/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_609.png: 640x640 (no detections), 7.0ms\n",
      "image 233/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_610.png: 640x640 18 PVegs, 5.1ms\n",
      "image 234/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_611.png: 640x640 12 PVegs, 1 Water, 5.6ms\n",
      "image 235/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_612.png: 640x640 25 PVegs, 1 Water, 5.7ms\n",
      "image 236/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_613.png: 640x640 15 PVegs, 5.6ms\n",
      "image 237/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_614.png: 640x640 7 PVegs, 5.8ms\n",
      "image 238/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_615.png: 640x640 2 PVegs, 5.1ms\n",
      "image 239/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_640.png: 640x640 8 PVegs, 5.0ms\n",
      "image 240/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_641.png: 640x640 13 PVegs, 5.7ms\n",
      "image 241/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_642.png: 640x640 17 PVegs, 5.0ms\n",
      "image 242/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_643.png: 640x640 7 PVegs, 5.0ms\n",
      "image 243/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_76.png: 640x640 (no detections), 5.1ms\n",
      "image 244/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_77.png: 640x640 (no detections), 4.9ms\n",
      "image 245/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_78.png: 640x640 (no detections), 4.9ms\n",
      "image 246/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_79.png: 640x640 15 PVegs, 4.9ms\n",
      "image 247/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_80.png: 640x640 18 PVegs, 5.8ms\n",
      "image 248/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_81.png: 640x640 24 PVegs, 5.7ms\n",
      "image 249/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_82.png: 640x640 15 PVegs, 5.8ms\n",
      "image 250/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_83.png: 640x640 15 PVegs, 5.6ms\n",
      "image 251/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_84.png: 640x640 17 PVegs, 5.6ms\n",
      "image 252/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_85.png: 640x640 14 PVegs, 5.7ms\n",
      "image 253/253 /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/tiled/images/chip_86.png: 640x640 4 PVegs, 5.8ms\n",
      "Speed: 2.1ms preprocess, 5.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/znelson/TensorStream/Labeled Data/Flight_2_25pct/predictions/predict_txt\u001b[0m\n",
      "238 labels saved to /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/predictions/predict_txt/labels\n",
      "‚úÖ Inference complete. Labels saved to: /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/predictions\\predict_txt\\labels\\\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Config ---\n",
    "map_folder = \"Flight_2_25pct\"\n",
    "image_dir = f\"/home/znelson/TensorStream/Labeled Data/{map_folder}/tiled/images\"\n",
    "\n",
    "# Absolute path to trained model\n",
    "model_path = f\"/home/znelson/TensorStream/Labeled Data/runs/segment/train/yolov8s_1600to1024_model01/weights/best.pt\"\n",
    "\n",
    "# Output folder for predictions\n",
    "output_dir = f\"/home/znelson/TensorStream/Labeled Data/{map_folder}/predictions\"\n",
    "output_name = \"predict_txt\"\n",
    "\n",
    "# --- Load model directly ---\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# --- Optional: Clean up old predictions ---\n",
    "label_dir = os.path.join(output_dir, output_name, \"labels\")\n",
    "if os.path.exists(label_dir):\n",
    "    old_labels = glob.glob(os.path.join(label_dir, \"*.txt\"))\n",
    "    for f in old_labels:\n",
    "        os.remove(f)\n",
    "    print(f\"üßπ Cleared {len(old_labels)} old prediction files from: {label_dir}\")\n",
    "\n",
    "# --- Predict with streaming ---\n",
    "results = model.predict(\n",
    "    source=image_dir,\n",
    "    imgsz=1024,\n",
    "    conf=0.3,\n",
    "    iou=0.3,\n",
    "    save=False,\n",
    "    save_txt=True,\n",
    "    save_conf=False,\n",
    "    retina_masks=True,\n",
    "    exist_ok=True,\n",
    "    project=output_dir,\n",
    "    name=output_name,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Force the generator to run\n",
    "for _ in results:\n",
    "    pass\n",
    "\n",
    "print(f\"‚úÖ Inference complete. Labels saved to: {output_dir}\\\\{output_name}\\\\labels\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29017713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stitching Tiles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 667/667 [00:24<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shapefile saved to: /home/znelson/TensorStream/Labeled Data/Flight_2_25pct/Flight_2_25pct Segmentation.shp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Config ---\n",
    "map_folder = \"Flight_2_25pct\"\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/{map_folder}\"\n",
    "mask_dir = os.path.join(base_dir, \"predictions\", \"predict_txt\", \"labels\")\n",
    "tile_metadata_path = os.path.join(base_dir, \"tiled\", \"tile_metadata.csv\")\n",
    "raster_shape_path = os.path.join(base_dir, \"tiled\", \"raster_shape.txt\")\n",
    "tif_path = os.path.join(base_dir, f\"{map_folder}.tiff\")\n",
    "shapefile_path = os.path.join(base_dir, f\"{map_folder} Segmentation.shp\")\n",
    "\n",
    "chip_size = 1600         # Original chip size used during tiling\n",
    "inference_size = 1024    # YOLOv8 inference resolution\n",
    "\n",
    "# Optional: Remap YOLO class IDs ‚Üí Original class IDs\n",
    "reverse_remap = {\n",
    "    0: 1,  # Road\n",
    "    1: 2,  # PVeg\n",
    "    2: 3   # Water\n",
    "}\n",
    "\n",
    "# --- Load metadata and raster georeferencing ---\n",
    "tile_meta = pd.read_csv(tile_metadata_path)\n",
    "with open(raster_shape_path, \"r\") as f:\n",
    "    height, width = map(int, f.read().strip().split(\",\"))\n",
    "\n",
    "with rasterio.open(tif_path) as src:\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "# --- Collect all polygons from predicted labels ---\n",
    "features = []\n",
    "\n",
    "for _, row in tqdm(tile_meta.iterrows(), total=len(tile_meta), desc=\"Stitching Tiles\"):\n",
    "    fname, x, y = row[\"filename\"], int(row[\"x\"]), int(row[\"y\"])\n",
    "    label_path = os.path.join(mask_dir, fname.replace(\".png\", \".txt\"))\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 7:\n",
    "            continue  # Skip degenerate polygons\n",
    "\n",
    "        cls_id = int(float(parts[0]))  # Already YOLO-aligned: 0 = Road, 1 = PVeg, 2 = Water\n",
    "\n",
    "        coords = list(map(float, parts[1:]))\n",
    "        pts = np.array(coords, dtype=np.float32).reshape(-1, 2)\n",
    "        pts *= chip_size  # Rescale to original resolution\n",
    "\n",
    "        pts[:, 0] += x\n",
    "        pts[:, 1] += y\n",
    "\n",
    "        geo_pts = [rasterio.transform.xy(transform, y_, x_, offset='center') for x_, y_ in pts]\n",
    "        poly = Polygon(geo_pts)\n",
    "\n",
    "        if poly.is_valid and poly.area > 0:\n",
    "            features.append({\n",
    "                \"geometry\": poly,\n",
    "                \"class_id\": reverse_remap.get(cls_id, cls_id)  # Optional remap\n",
    "            })\n",
    "\n",
    "# --- Export to shapefile ---\n",
    "gdf = gpd.GeoDataFrame(features, crs=crs)\n",
    "gdf.to_file(shapefile_path)\n",
    "\n",
    "print(f\"‚úÖ Shapefile saved to: {shapefile_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62dc9c-bec3-47a6-a662-7e4a0aa34949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "map_folder = \"Flight_2_25pct\"\n",
    "base_dir = f\"/home/znelson/TensorStream/Labeled Data/{map_folder}\"\n",
    "\n",
    "reverse_remap = {\n",
    "    0: \"Road\",\n",
    "    1: \"PVeg\",\n",
    "    2: \"Water\"\n",
    "}\n",
    "\n",
    "# --- Calculate areas for each map ---\n",
    "print(f\"Calculating areas for: {map_folder}\")\n",
    "base_map_dir = os.path.join(base_dir, map_folder)\n",
    "tif_path = os.path.join(base_map_dir, f\"{map_folder}.tiff\")\n",
    "mask_dir = os.path.join(base_map_dir, \"predictions\", \"predict_txt\", \"labels\")\n",
    "tile_metadata_path = os.path.join(base_map_dir, \"tiled\", \"tile_metadata.csv\")\n",
    "area_csv_path = os.path.join(base_map_dir, f\"{map_folder}_area_summary.csv\")\n",
    "\n",
    "# --- Extract GSD from GeoTIFF ---\n",
    "with rasterio.open(tif_path) as src:\n",
    "    gsd_x = abs(src.transform.a)  # Meters per pixel (x direction)\n",
    "    gsd_y = abs(src.transform.e)  # Meters per pixel (y direction)\n",
    "    sqft_per_pixel = (gsd_x * gsd_y) * 10.7639  # Correct area calculation\n",
    "\n",
    "print(f\"üåé {map_folder} GSD: {gsd_x:.4f} x {gsd_y:.4f} meters per pixel ({sqft_per_pixel:.4f} sqft per pixel)\")\n",
    "\n",
    "# --- Collect pixel counts per class ---\n",
    "class_areas = {\"Road\": 0, \"PVeg\": 0, \"Water\": 0}\n",
    "tile_meta = pd.read_csv(tile_metadata_path)\n",
    "for _, row in tile_meta.iterrows():\n",
    "    fname, x, y = row[\"filename\"], int(row[\"x\"]), int(row[\"y\"])\n",
    "    label_path = os.path.join(mask_dir, fname.replace(\".png\", \".txt\"))\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 7:\n",
    "                continue  # Skip degenerate polygons\n",
    "\n",
    "            cls_id = int(float(parts[0]))\n",
    "            original_class = reverse_remap.get(cls_id, cls_id)\n",
    "            pixel_count = (len(parts) - 1) // 2  # Each (x, y) pair is 2 coordinates\n",
    "\n",
    "            # Accumulate area\n",
    "            class_areas[original_class] += pixel_count\n",
    "\n",
    "# --- Convert to square feet and round ---\n",
    "class_areas_sqft = {\n",
    "    cls_name: round(count * sqft_per_pixel)\n",
    "    for cls_name, count in class_areas.items()\n",
    "}\n",
    "\n",
    "# --- Save CSV for client ---\n",
    "if os.path.exists(area_csv_path):\n",
    "    os.remove(area_csv_path)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"label_name\": cls_name, \"area_sqft\": area}\n",
    "    for cls_name, area in class_areas_sqft.items()\n",
    "]).to_csv(area_csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ {map_folder} area CSV saved to: {area_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29de1179-a660-4c39-bcf2-5d1f8181bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 Road-heavy tiles.\n",
      "‚úÖ Duplicated 530 files across 212 tiles\n"
     ]
    }
   ],
   "source": [
    "# SCRIPT TO FIND AND DUPLICATE ROAD CHIPS (WITH SAFETY CHECK)\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "train_lbl_dir = \"/home/znelson/TensorStream/Labeled Data/dataset/labels/train\"\n",
    "train_img_dir = \"/home/znelson/TensorStream/Labeled Data/dataset/images/train\"\n",
    "\n",
    "# Set how many total copies (not additional) you want per qualifying tile\n",
    "copies_per_tile = 3  # e.g., 3 means 1 original + 3 duplicates = 4 total versions\n",
    "\n",
    "# Find Road-heavy tiles (YOLO class ID 0)\n",
    "road_heavy_tiles = []\n",
    "for fname in os.listdir(train_lbl_dir):\n",
    "    if not fname.endswith(\".txt\"):\n",
    "        continue\n",
    "    path = os.path.join(train_lbl_dir, fname)\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    count = Counter(int(line.split()[0]) for line in lines if line.strip())\n",
    "    if count.get(0, 0) >= 3:  # Adjust this threshold if needed\n",
    "        road_heavy_tiles.append(fname.replace(\".txt\", \"\"))\n",
    "\n",
    "print(f\"Found {len(road_heavy_tiles)} Road-heavy tiles.\")\n",
    "\n",
    "# Duplicate each qualifying tile safely\n",
    "duplication_count = 0\n",
    "for tile_name in road_heavy_tiles:\n",
    "    img_path = os.path.join(train_img_dir, tile_name + \".png\")\n",
    "    lbl_path = os.path.join(train_lbl_dir, tile_name + \".txt\")\n",
    "    \n",
    "    for i in range(1, copies_per_tile + 1):\n",
    "        new_suffix = f\"_dup{i}\"\n",
    "        new_img = os.path.join(train_img_dir, tile_name + new_suffix + \".png\")\n",
    "        new_lbl = os.path.join(train_lbl_dir, tile_name + new_suffix + \".txt\")\n",
    "        \n",
    "        if not os.path.exists(new_img) and not os.path.exists(new_lbl):\n",
    "            shutil.copyfile(img_path, new_img)\n",
    "            shutil.copyfile(lbl_path, new_lbl)\n",
    "            duplication_count += 1\n",
    "\n",
    "print(f\"‚úÖ Duplicated {duplication_count} files across {len(road_heavy_tiles)} tiles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
