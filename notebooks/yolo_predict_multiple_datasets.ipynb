{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from importlib import reload\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Clone georip repo here: https://www.github.com/joeletho/georip.git\n",
    "\n",
    "# Cloned repo directory\n",
    "sys.path.append(\"path/to/georip\")\n",
    "\n",
    "import georip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n"
     ]
    }
   ],
   "source": [
    "# BLANK\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'georip.georip' from '/home/joel/Dev/python/georip/georip.py'>\n",
      "<module 'georip.utils' from '/home/joel/Dev/python/georip/utils.py'>\n",
      "<module 'georip.modeling' from '/home/joel/Dev/python/georip/modeling/__init__.py'>\n",
      "<module 'georip.modeling.yolo' from '/home/joel/Dev/python/georip/modeling/yolo.py'>\n"
     ]
    }
   ],
   "source": [
    "# BLANK\n",
    "print(reload(georip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# BLANK\n",
    "has_gpu = cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if has_gpu else 'cpu')\n",
    "print(device)\n",
    "if has_gpu:\n",
    "    print(cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Example directory structure:\n",
    "```\n",
    "Root\n",
    "  ├── GEORIP_YOLO\n",
    "  |         ├── datasets\n",
    "  |         ├── models\n",
    "  ├── NDVI\n",
    "  ├── QGIS\n",
    "  ├── Readme.txt\n",
    "  ├── Shapefiles\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "glo7hYL73EVo"
   },
   "outputs": [],
   "source": [
    "# BLANK\n",
    "path_map = {}\n",
    "\n",
    "# Change this to your project path\n",
    "path_map['ROOT'] = Path(\"path/to/project/root\")\n",
    "\n",
    "path_map['RESULTS'] = path_map['ROOT'] / 'results'\n",
    "path_map['PROJECT_NAME'] = 'GEORIP_YOLO'\n",
    "path_map['georip'] = path_map['ROOT'] / path_map[\"PROJECT_NAME\"]\n",
    "path_map['GEORIP_DS'] = path_map['georip'] / 'datasets'\n",
    "path_map['GEORIP_MODELS'] = path_map['georip'] / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory structure\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/NDVI/NDVI Difference Rasters\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/Shapefiles\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/GEORIP_YOLO/datasets/meta\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/GEORIP_YOLO/datasets/meta/csv\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/GEORIP_YOLO/datasets/meta/shp\n",
      "   /home/joel/Dev/school/ssu-ai/ForestTreatment-CNN/Shapefiles/ModelPredictions\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# BLANK\n",
    "def make_directories(paths_map, verbose=True, exist_ok=False):\n",
    "    if verbose:\n",
    "        print(\"Creating directory structure\")\n",
    "    for name, path in paths_map.items():\n",
    "        if isinstance(path, Path):\n",
    "            if path.is_file() or len(path.suffix) > 0:\n",
    "                paths_map[name] = path.resolve()\n",
    "            else:\n",
    "                path = path.resolve()\n",
    "                paths_map[name] = path\n",
    "                path.mkdir(parents=True, exist_ok=exist_ok)\n",
    "                if verbose:\n",
    "                    print('  ',path)\n",
    "    if verbose:\n",
    "        print(\"Complete\")\n",
    "\n",
    "def make_project_paths(root,*, verbose=True, exist_ok=False):    \n",
    "    paths = {'NDVI': Path(root, 'NDVI', 'NDVI Difference Rasters')}\n",
    "    paths['SHAPE_FILES'] = Path(root, 'Shapefiles')\n",
    "\n",
    "    paths['GEORIP_DS_META'] = path_map['georip_DS'] / 'meta'\n",
    "    paths['GEORIP_DS_CSV'] = paths['georip_DS_META'] / 'csv'\n",
    "    paths['GEORIP_DS_SHP'] = paths['georip_DS_META'] / 'shp'\n",
    "    \n",
    "    # Data\n",
    "    paths['PRED_SHP'] = paths['SHAPE_FILES'] / 'ModelPredictions'\n",
    "    paths['SHPZ10_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz10_Only_08-18-24' / 'Treatments_UTMz10_Only_08-18-24.shp'\n",
    "    paths['SHPZ11_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz11_Only_08-18-24' / 'Treatments_UTMz11_Only_08-18-24.shp'\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "        \n",
    "def make_dataset_paths(ds_root, models_root, model_name, *,verbose=True, exist_ok=False):\n",
    "    ds_root = Path(ds_root)\n",
    "    models_root = Path(models_root)\n",
    "    paths = {}\n",
    "        \n",
    "    paths['MODEL_NAME'] = model_name\n",
    "    paths['GEORIP_MODEL'] = models_root / paths['MODEL_NAME']\n",
    "    paths['GEORIP_DS_MODEL'] = ds_root / paths['MODEL_NAME']\n",
    "    paths['GEORIP_DS_MODEL_META'] = paths['georip_DS_MODEL'] / 'meta'\n",
    "    paths['GEORIP_DS_MODEL_SHP'] = paths['georip_DS_MODEL_META'] / 'shp'\n",
    "    paths['GEORIP_DS_MODEL_CSV'] = paths['georip_DS_MODEL_META'] / 'csv'\n",
    "    \n",
    "    paths['GEORIP_DS_DATA'] = paths['georip_DS_MODEL'] / 'meta'\n",
    "    paths['GEORIP_DS_CONFIG_FILE'] = paths['georip_DS_MODEL'] / 'config' / 'data.yaml'\n",
    "    paths['GEORIP_DS_YOLO_DATA_FILE'] = paths['georip_DS_DATA'] / 'yolo_ndvi_ds.csv'\n",
    "    \n",
    "    # Images and labels\n",
    "    paths['GEORIP_DS_IMAGES'] = paths['georip_DS_MODEL'] / 'images'\n",
    "    paths['GEORIP_DS_LABELS'] = paths['georip_DS_MODEL'] / 'labels'\n",
    "    paths['GEORIP_DS_LABELS_GENERATED'] = paths['georip_DS_LABELS'] / 'generated'\n",
    "    \n",
    "    paths['GEORIP_DS_CHIPS'] = paths[\"georip_DS_IMAGES\"] / 'chips'\n",
    "    paths['GEORIP_DS_PNGS'] = paths[\"georip_DS_IMAGES\"] / 'png'\n",
    "    paths['GEORIP_DS_TIFS'] = paths[\"georip_DS_IMAGES\"] / 'tif'\n",
    "    \n",
    "    paths['GEORIP_DS_IMAGES_TRAIN'] = paths['georip_DS_IMAGES'] / 'train'\n",
    "    paths['GEORIP_DS_IMAGES_TEST'] = paths['georip_DS_IMAGES'] / 'test'\n",
    "    paths['GEORIP_DS_IMAGES_VAL'] = paths['georip_DS_IMAGES'] / 'val'\n",
    "    \n",
    "    paths['GEORIP_DS_LABELS_TRAIN'] = paths['georip_DS_LABELS'] / 'train'\n",
    "    paths['GEORIP_DS_LABELS_TEST'] = paths['georip_DS_LABELS'] / 'test'\n",
    "    paths['GEORIP_DS_LABELS_VAL'] = paths['georip_DS_LABELS'] / 'val'\n",
    "\n",
    "    # Metadata\n",
    "\n",
    "    # Zone 10\n",
    "    paths['CSVZ10'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz10.csv'\n",
    "    paths['CSVZ10_NORM'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized.csv'\n",
    "    paths['CSVZ10_CLEANED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized_cleaned.csv'\n",
    "    paths['CSVZ10_CHIPPED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized_chipped.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_UTM'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z10utm_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL_ENCODED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PREYOLO'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels_encoded_preyolo.csv'\n",
    "    \n",
    "    # Zone 11\n",
    "    paths['CSVZ11'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz11.csv'\n",
    "    paths['CSVZ11_NORM'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized.csv'\n",
    "    paths['CSVZ11_CLEANED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized_cleaned.csv'\n",
    "    paths['CSVZ11_CHIPPED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized_chipped.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_UTM'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z11utm_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL_ENCODED'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PREYOLO'] = paths['GEORIP_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels_encoded_preyolo.csv'\n",
    "\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    \n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "    path_map['SHPZ10_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz10_{paths['MODEL_NAME']}.shp\"\n",
    "    path_map['SHPZ11_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz11_{paths['MODEL_NAME']}.shp\"\n",
    "\n",
    "make_project_paths(path_map['ROOT'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "CONF=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "print(path_map['RESULTS'])\n",
    "\n",
    "dirs = []\n",
    "for path in path_map['RESULTS'].iterdir():\n",
    "    if path.is_file():\n",
    "        continue\n",
    "    dirs.append(path)\n",
    "\n",
    "n_dirs = 0\n",
    "for dir in dirs:\n",
    "    n_dirs += len(os.listdir(dir))\n",
    "    \n",
    "pbar = trange(n_dirs, desc='Predicting on model results')\n",
    "\n",
    "for dir in dirs:\n",
    "    for res_dir in dir.iterdir():\n",
    "        if res_dir.is_file():\n",
    "            pbar.update()\n",
    "            continue\n",
    "            \n",
    "        model_name = res_dir.name\n",
    "        years = None\n",
    "        parts = model_name.split('_')\n",
    "        for part in parts:\n",
    "            if part.startswith('years'):\n",
    "                years = part.split('=')[1]\n",
    "        if years is None:\n",
    "            raise ValueError(f\"Error parsing 'years' in '{model_name}'\")\n",
    "    \n",
    "        args_path = res_dir / 'train' / 'args.yaml'\n",
    "        if not args_path.exists():\n",
    "            raise FileNotFoundError(args_path)\n",
    "    \n",
    "        imgsz = None\n",
    "        batchsz = None\n",
    "        with open(args_path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip('\\n').split(':')\n",
    "                parts[0] = parts[0].strip()\n",
    "                parts[1] = parts[1].strip()\n",
    "                if parts[0] == 'imgsz':\n",
    "                    imgsz = int(parts[1])\n",
    "                elif parts[0] == 'batch':\n",
    "                    batchsz= max(1, int(parts[1])-2)\n",
    "        if imgsz is None:\n",
    "            raise ValueError(f\"Error parsing image size in '{args_path}'\")\n",
    "        if batchsz is None:\n",
    "            raise ValueError(f\"Error parsing batch size in '{args_path}'\")\n",
    "    \n",
    "        model_path = res_dir / 'train' / 'weights' / 'best.pt'\n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(model_path)\n",
    "    \n",
    "        model = YOLO(model_path)\n",
    "        model.to('cuda')\n",
    "        \n",
    "        imgs = [img for img in georip.io.collect_files_with_suffix(\".tif\", path_map['NDVI']) if years in str(img)]\n",
    "        results, gdfs = georip.modeling.yolo.predict_geotiffs(\n",
    "            model,\n",
    "            imgs,\n",
    "            confidence=CONF, \n",
    "            chip_size=(imgsz, imgsz), \n",
    "            imgsz=imgsz,\n",
    "            device=0,\n",
    "            max_images=1,\n",
    "            batch_size=batchsz,\n",
    "        )\n",
    "        print(f\"Processed {model_name}. Saving...\", end=' ')\n",
    "        for i, gdf in enumerate(gdfs):\n",
    "            georip.io.save_as_shp(gdf, path_map['PRED_SHP'] / model_name / f'TreamentPredictions_{i}_conf={CONF}.shp', exist_ok=True)\n",
    "        print(f\"saved {len(gdf)} files\")\n",
    "        pbar.update()\n",
    "        \n",
    "pbar.set_description(\"Complete\")\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
